{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow's `Dataset` API\n",
    "\n",
    "This notebook contains examples on how to build simple input pipelines with TensorFlow's [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data/) API. The examples are based on contructing `Dataset` objects from Numpy arrays in memory, which is intended to be used only with very small datasets as it can be considerably inefficient.\n",
    "\n",
    "More info can be found on the session [Importing Data](https://www.tensorflow.org/guide/datasets) on TensorFlow's page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data\n",
    "nsamples = 10\n",
    "nfeatures = 4\n",
    "x_numpy = np.random.random((nsamples, nfeatures))\n",
    "y_numpy = x_numpy.sum(axis=1).astype(int)\n",
    "\n",
    "# Check the y values\n",
    "# np.unique(y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a `Dataset` object\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_numpy, y_numpy))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()\n",
    "\n",
    "# * Dataset.repeat() concatenates the datataset without signaling the end of one epoch\n",
    "#   and the beginning of the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_classes: (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'tensorflow.python.framework.ops.Tensor'>)\n",
      "output_shapes:  (TensorShape([Dimension(None), Dimension(4)]), TensorShape([Dimension(None)]))\n",
      "output_types:   (tf.float64, tf.int64)\n"
     ]
    }
   ],
   "source": [
    "# This properties of a Dataset instance allow you to inspect\n",
    "# the types, classes (they are allways Tensor though) and\n",
    "# shapes of the components of a dataset element.\n",
    "print('output_classes:', dataset.output_classes)\n",
    "print('output_shapes: ', dataset.output_shapes)\n",
    "print('output_types:  ', dataset.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: [[0.08979985 0.48339875 0.50210204 0.88801814]]  |  label: [1]\n",
      "features: [[0.03819731 0.01846576 0.10768675 0.00198685]]  |  label: [0]\n",
      "features: [[0.74537316 0.17139221 0.36994259 0.17733685]]  |  label: [1]\n",
      "features: [[0.30423547 0.08525225 0.51536512 0.04312901]]  |  label: [0]\n",
      "features: [[0.41625645 0.44135946 0.08748522 0.58499039]]  |  label: [1]\n",
      "features: [[0.16022997 0.29757888 0.98556616 0.36110203]]  |  label: [1]\n",
      "features: [[0.79684992 0.59123642 0.48409895 0.56672481]]  |  label: [2]\n",
      "features: [[0.0429743  0.53089394 0.79250231 0.92004754]]  |  label: [2]\n",
      "features: [[0.94971716 0.68010704 0.81005402 0.18546125]]  |  label: [2]\n",
      "features: [[0.70738882 0.64529225 0.48295785 0.2769267 ]]  |  label: [2]\n"
     ]
    }
   ],
   "source": [
    "# If the iterator reaches the end of the dataset (with all the repeats),\n",
    "# executing the `next_item` operation will raise a `tf.errors.OutOfRangeError`.\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        features, label = sess.run(next_item)\n",
    "        print('features: %s  |  label: %s' % (features, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: [[0.70738882 0.64529225 0.48295785 0.2769267 ]]  |  label: [2]\n",
      "features: [[0.79684992 0.59123642 0.48409895 0.56672481]]  |  label: [2]\n",
      "features: [[0.03819731 0.01846576 0.10768675 0.00198685]]  |  label: [0]\n",
      "features: [[0.94971716 0.68010704 0.81005402 0.18546125]]  |  label: [2]\n",
      "features: [[0.08979985 0.48339875 0.50210204 0.88801814]]  |  label: [1]\n",
      "features: [[0.74537316 0.17139221 0.36994259 0.17733685]]  |  label: [1]\n",
      "features: [[0.30423547 0.08525225 0.51536512 0.04312901]]  |  label: [0]\n",
      "features: [[0.16022997 0.29757888 0.98556616 0.36110203]]  |  label: [1]\n",
      "features: [[0.41625645 0.44135946 0.08748522 0.58499039]]  |  label: [1]\n",
      "features: [[0.0429743  0.53089394 0.79250231 0.92004754]]  |  label: [2]\n",
      "The dataset ran out of entries!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            features, label = sess.run(next_item)\n",
    "            print('features: %s  |  label: %s' % (features, label))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('The dataset ran out of entries!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "features: [[0.0429743  0.53089394 0.79250231 0.92004754]]  |  label: [2]\n",
      "features: [[0.41625645 0.44135946 0.08748522 0.58499039]]  |  label: [1]\n",
      "features: [[0.74537316 0.17139221 0.36994259 0.17733685]]  |  label: [1]\n",
      "features: [[0.08979985 0.48339875 0.50210204 0.88801814]]  |  label: [1]\n",
      "features: [[0.79684992 0.59123642 0.48409895 0.56672481]]  |  label: [2]\n",
      "features: [[0.70738882 0.64529225 0.48295785 0.2769267 ]]  |  label: [2]\n",
      "features: [[0.94971716 0.68010704 0.81005402 0.18546125]]  |  label: [2]\n",
      "features: [[0.30423547 0.08525225 0.51536512 0.04312901]]  |  label: [0]\n",
      "features: [[0.16022997 0.29757888 0.98556616 0.36110203]]  |  label: [1]\n",
      "features: [[0.03819731 0.01846576 0.10768675 0.00198685]]  |  label: [0]\n"
     ]
    }
   ],
   "source": [
    "# tf.errors.OutOfRangeError:\n",
    "# `tf.train.MonitoredTrainingSession` is necessary when running distributed training\n",
    "# with TensorFlow. It uses tf.errors.OutOfRangeError to identify the last iteration\n",
    "# automatically.\n",
    "\n",
    "with tf.train.MonitoredTrainingSession() as sess:\n",
    "    while not sess.should_stop():\n",
    "        features, label = sess.run(next_item)\n",
    "        print('features: %s  |  label: %s' % (features, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Dataset` object can be created also from Tensor objects\n",
    "\n",
    "If the input pipeline depends now on TensorFlow operations, like on the followin cell, for instance, we need to use an **initializable iterator** instead of a **one-shot** one and run `sess.run(iterator.initializer)` befor start iterating. This will perform the graph operations (in this case evalate the tesnors) and that will be needed in the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.random.uniform([nsamples, nfeatures])\n",
    "y_tensor = tf.cast(tf.reduce_sum(x_tensor, axis=1), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "features: [[0.8323463  0.19634986 0.28265893 0.58835554]]  |  label: [1]\n",
      "features: [[0.5557394  0.15045857 0.42133427 0.57148683]]  |  label: [1]\n",
      "features: [[0.07681918 0.48761415 0.34690034 0.07560027]]  |  label: [0]\n",
      "features: [[0.6231345  0.12168407 0.82891834 0.4291649 ]]  |  label: [2]\n",
      "features: [[0.54758704 0.5609318  0.51281536 0.20193076]]  |  label: [1]\n",
      "features: [[0.9646871  0.44459295 0.22541761 0.20803297]]  |  label: [1]\n",
      "features: [[0.4618914  0.38408446 0.47942042 0.77109647]]  |  label: [2]\n",
      "features: [[0.21837783 0.8274019  0.41136444 0.9828838 ]]  |  label: [2]\n",
      "features: [[0.55970013 0.93917    0.6917205  0.6595677 ]]  |  label: [2]\n",
      "features: [[0.7341771  0.6856011  0.17116964 0.85631883]]  |  label: [2]\n"
     ]
    }
   ],
   "source": [
    "with tf.train.MonitoredTrainingSession() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    while not sess.should_stop():\n",
    "        features, label = sess.run(next_item)\n",
    "        print('features: %s  |  label: %s' % (features, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`tf.data.Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) embeds the features and labels arrays in your TensorFlow graph as `tf.constant` operations. This works well for a small dataset, but wastes memory because the contents of the array will be copied multiple times.\n",
    "\n",
    "As an alternative, a **feedable** `Dataset` can be defined in terms of `tf.placeholder` tensors, and feed the NumPy arrays when an Iterator is initialized over the dataset. However this is still very ineficient!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_placeholder = tf.placeholder(x_numpy.dtype, x_numpy.shape)\n",
    "label_placeholder = tf.placeholder(y_numpy.dtype, y_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, label_placeholder))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)\n",
    "# transformations\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "features: [[0.03819731 0.01846576 0.10768675 0.00198685]]  |  label: [0]\n",
      "features: [[0.94971716 0.68010704 0.81005402 0.18546125]]  |  label: [2]\n",
      "features: [[0.30423547 0.08525225 0.51536512 0.04312901]]  |  label: [0]\n",
      "features: [[0.74537316 0.17139221 0.36994259 0.17733685]]  |  label: [1]\n",
      "features: [[0.41625645 0.44135946 0.08748522 0.58499039]]  |  label: [1]\n",
      "features: [[0.70738882 0.64529225 0.48295785 0.2769267 ]]  |  label: [2]\n",
      "features: [[0.16022997 0.29757888 0.98556616 0.36110203]]  |  label: [1]\n",
      "features: [[0.79684992 0.59123642 0.48409895 0.56672481]]  |  label: [2]\n",
      "features: [[0.0429743  0.53089394 0.79250231 0.92004754]]  |  label: [2]\n",
      "features: [[0.08979985 0.48339875 0.50210204 0.88801814]]  |  label: [1]\n"
     ]
    }
   ],
   "source": [
    "with tf.train.MonitoredTrainingSession() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={features_placeholder: x_numpy,\n",
    "                                              label_placeholder: y_numpy})\n",
    "    while not sess.should_stop():\n",
    "        features, label = sess.run(next_item)\n",
    "        print('features: %s  |  label: %s' % (features, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data transformations to the pipeline\n",
    "\n",
    "Lest's say that for our problem it is beneficial to center the features between -0.5 and 0.5. Also, we would like to transform the labels from integers to one-hot encoded. This is can be donde with `Dataset`'s method `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following transformations are quite simple and can be done\n",
    "# on a single function, but we will use two different functions\n",
    "# to show how operations can be pipelined.\n",
    "\n",
    "def center(*row):\n",
    "    features = row[0] - 0.5\n",
    "    label = row[1]\n",
    "    return features, label\n",
    "\n",
    "def make_on_hot_labels(features, label):\n",
    "    return features, tf.one_hot(label, 4)\n",
    "\n",
    "# simpler with `dataset = dataset.filter(lambda f, l: tf.equal(l, 1))`\n",
    "def filter_labels(features, label):\n",
    "    return tf.equal(label, 1)\n",
    "\n",
    "# simpler with `dataset = dataset.filter(lambda f, l: tf.greater(f[0], 0)`\n",
    "def filter_features(features, label):\n",
    "    return tf.greater(features[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_numpy, y_numpy))\n",
    "dataset = dataset.filter(filter_labels)\n",
    "dataset = dataset.map(center)\n",
    "dataset = dataset.filter(filter_features)\n",
    "dataset = dataset.map(make_on_hot_labels)\n",
    "dataset = dataset.shuffle(150)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)\n",
    "next_item = dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "features: [[ 0.24537316 -0.32860779 -0.13005741 -0.32266315]]  |  label: [[0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.train.MonitoredTrainingSession() as sess:\n",
    "    while not sess.should_stop():\n",
    "        features, label = sess.run(next_item)\n",
    "        print('features: %s  |  label: %s' % (features, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving names to `Dataset` components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_classes: {'features': <class 'tensorflow.python.framework.ops.Tensor'>, 'label': <class 'tensorflow.python.framework.ops.Tensor'>}\n",
      "output_shapes:  {'features': TensorShape([Dimension(4)]), 'label': TensorShape([])}\n",
      "output_types:   {'features': tf.float64, 'label': tf.int64}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'features': x_numpy, 'label': y_numpy})\n",
    "print('output_classes:', dataset.output_classes)\n",
    "print('output_shapes: ', dataset.output_shapes)\n",
    "print('output_types:  ', dataset.output_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(row):\n",
    "    features = row['features'] - 0.5\n",
    "    label = row['label']\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'features': x_numpy, 'label': y_numpy})\n",
    "dataset = dataset.map(center)\n",
    "dataset = dataset.shuffle(150)\n",
    "dataset = dataset.batch(1)   # batch size\n",
    "dataset = dataset.repeat(1)  # number of epochs\n",
    "next_item = dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "features: [[-0.19576453 -0.41474775  0.01536512 -0.45687099]]  |  label: [0]\n",
      "features: [[-0.46180269 -0.48153424 -0.39231325 -0.49801315]]  |  label: [0]\n",
      "features: [[ 0.20738882  0.14529225 -0.01704215 -0.2230733 ]]  |  label: [2]\n",
      "features: [[-0.33977003 -0.20242112  0.48556616 -0.13889797]]  |  label: [1]\n",
      "features: [[ 0.44971716  0.18010704  0.31005402 -0.31453875]]  |  label: [2]\n",
      "features: [[ 0.24537316 -0.32860779 -0.13005741 -0.32266315]]  |  label: [1]\n",
      "features: [[-0.4570257   0.03089394  0.29250231  0.42004754]]  |  label: [2]\n",
      "features: [[-0.41020015 -0.01660125  0.00210204  0.38801814]]  |  label: [1]\n",
      "features: [[-0.08374355 -0.05864054 -0.41251478  0.08499039]]  |  label: [1]\n",
      "features: [[ 0.29684992  0.09123642 -0.01590105  0.06672481]]  |  label: [2]\n"
     ]
    }
   ],
   "source": [
    "with tf.train.MonitoredTrainingSession() as sess:\n",
    "    while not sess.should_stop():\n",
    "        features, label = sess.run(next_item)\n",
    "        print('features: %s  |  label: %s' % (features, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
